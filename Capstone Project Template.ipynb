{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Movie-DB: A Centralized Movie Database\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "This database combines several ratings to create a centralized movie database. The database can be used for recommender systems, entertainment apps which require movie-data analytics or even for personal use when searching for a movie to watch. I use publicly available datasets on IMDb, RottenTomatoes, Oscars, Golden Globes from Kaggle and IMDb website to create the database. \n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Package Management for the Project\n",
    "Since we load parquet file, I need to install fastparquet, which can be used by Pandas to read in the data. For that, we upgrade Numpy and then install fastparquet. We then import the necessary libraries needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/b2/6c7545bb7a38754d63048c7696804a0d947328125d81bf12beaa692c3ae3/numpy-1.19.5-cp36-cp36m-manylinux1_x86_64.whl (13.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 13.4MB 1.2MB/s eta 0:00:01   16% |█████▏                          | 2.2MB 4.3MB/s eta 0:00:03    22% |███████▎                        | 3.1MB 18.8MB/s eta 0:00:01    43% |██████████████                  | 5.9MB 18.4MB/s eta 0:00:01    57% |██████████████████▎             | 7.7MB 19.7MB/s eta 0:00:01    88% |████████████████████████████▌   | 11.9MB 18.4MB/s eta 0:00:01\n",
      "\u001b[31mtensorflow 1.3.0 requires tensorflow-tensorboard<0.2.0,>=0.1.0, which is not installed.\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "  Found existing installation: numpy 1.12.1\n",
      "    Uninstalling numpy-1.12.1:\n",
      "      Successfully uninstalled numpy-1.12.1\n",
      "Successfully installed numpy-1.19.5\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fastparquet\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a2/7d/11379030c56ea8bce7765732a8f7697713899109e6a04184b7dca92b293d/fastparquet-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (1.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.2MB 10.7MB/s ta 0:00:01    61% |███████████████████▉            | 727kB 15.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting fsspec (from fastparquet)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/e1/7111d8afc76ee3171f4f99592cd29bac9d233ae1aa34623011506f955434/fsspec-2021.7.0-py3-none-any.whl (118kB)\n",
      "\u001b[K    100% |████████████████████████████████| 122kB 17.6MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting pandas>=1.1.0 (from fastparquet)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/e2/00cacecafbab071c787019f00ad84ca3185952f6bb9bca9550ed83870d4d/pandas-1.1.5-cp36-cp36m-manylinux1_x86_64.whl (9.5MB)\n",
      "\u001b[K    100% |████████████████████████████████| 9.5MB 3.2MB/s eta 0:00:01   4% |█▎                              | 389kB 19.2MB/s eta 0:00:01    13% |████▌                           | 1.3MB 19.1MB/s eta 0:00:01    43% |█████████████▉                  | 4.1MB 21.1MB/s eta 0:00:01    53% |█████████████████               | 5.1MB 17.5MB/s eta 0:00:01    62% |████████████████████            | 5.9MB 19.2MB/s eta 0:00:01    83% |██████████████████████████▋     | 7.9MB 18.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting thrift>=0.11.0 (from fastparquet)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/97/1e/3284d19d7be99305eda145b8aa46b0c33244e4a496ec66440dac19f8274d/thrift-0.13.0.tar.gz (59kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 10.8MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting cramjam>=2.3.0 (from fastparquet)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2f/91/b6d5795682e70c3c2461b972a35ec68a7da1eed0e2cd772c9fecea582d91/cramjam-2.3.2-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.5MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.5MB 10.3MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.11 in /opt/conda/lib/python3.6/site-packages (from fastparquet) (1.19.5)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.6/site-packages (from pandas>=1.1.0->fastparquet) (2017.3)\n",
      "Collecting python-dateutil>=2.7.3 (from pandas>=1.1.0->fastparquet)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/7a/87837f39d0296e723bb9b62bbb257d0355c7f6128853c78955f57342a56d/python_dateutil-2.8.2-py2.py3-none-any.whl (247kB)\n",
      "\u001b[K    100% |████████████████████████████████| 256kB 10.3MB/s ta 0:00:01    74% |███████████████████████▉        | 184kB 20.3MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.7.2 in /opt/conda/lib/python3.6/site-packages (from thrift>=0.11.0->fastparquet) (1.11.0)\n",
      "Building wheels for collected packages: thrift\n",
      "  Running setup.py bdist_wheel for thrift ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/02/a2/46/689ccfcf40155c23edc7cdbd9de488611c8fdf49ff34b1706e\n",
      "Successfully built thrift\n",
      "Installing collected packages: fsspec, python-dateutil, pandas, thrift, cramjam, fastparquet\n",
      "  Found existing installation: python-dateutil 2.6.1\n",
      "    Uninstalling python-dateutil-2.6.1:\n",
      "      Successfully uninstalled python-dateutil-2.6.1\n",
      "  Found existing installation: pandas 0.23.3\n",
      "    Uninstalling pandas-0.23.3:\n",
      "      Successfully uninstalled pandas-0.23.3\n",
      "Successfully installed cramjam-2.3.2 fastparquet-0.7.0 fsspec-2021.7.0 pandas-1.1.5 python-dateutil-2.8.2 thrift-0.13.0\n"
     ]
    }
   ],
   "source": [
    "!pip install fastparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# All the imports are done here\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "import fastparquet\n",
    "import psycopg2\n",
    "from sql_queries import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#This is needed when copying directly from numpy, since Postgres only supports native Python formats\n",
    "import numpy as np\n",
    "from psycopg2.extensions import register_adapter, AsIs\n",
    "\n",
    "def addapt_numpy_float64(numpy_float64):\n",
    "    return AsIs(numpy_float64)\n",
    "\n",
    "def addapt_numpy_int64(numpy_int64):\n",
    "    return AsIs(numpy_int64)\n",
    "\n",
    "def addapt_numpy_float32(numpy_float32):\n",
    "    return AsIs(numpy_float32)\n",
    "\n",
    "def addapt_numpy_int32(numpy_int32):\n",
    "    return AsIs(numpy_int32)\n",
    "\n",
    "def addapt_numpy_array(numpy_array):\n",
    "    return AsIs(tuple(numpy_array))\n",
    "\n",
    "register_adapter(np.float64, addapt_numpy_float64)\n",
    "register_adapter(np.int64, addapt_numpy_int64)\n",
    "register_adapter(np.float32, addapt_numpy_float32)\n",
    "register_adapter(np.int32, addapt_numpy_int32)\n",
    "register_adapter(np.ndarray, addapt_numpy_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "We will now create a database called moviedb, and create the necessary tables. This is all taken care of using some SQL queries which are defined in sql_queries.py. We have to run create_tables first, and only then proceed with the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "%run create_tables.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Connecting to the database created in create_tables.py\n",
    "conn = psycopg2.connect(\"host=127.0.0.1 dbname=moviedb user=student password=student\")\n",
    "conn.set_session(autocommit=True)\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def convert_nan(df):\n",
    "    \"\"\"\n",
    "    This function converts nulls in a Pandas dataset to None object, which when saved in a CSV is blank. \n",
    "    This is done so that when the CSV is loaded, we correctly classify NULL using \"\"\n",
    "    Input: A dataframe which contains some nulls\n",
    "    Output: A dataframe in which all nulls are now None object\n",
    "    \"\"\"\n",
    "    return df.where(pd.notnull(df), None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Step 1: Scope the Project and Gather Data\n",
    "\n",
    "## Scope \n",
    "The database will contain information about movies, so TV Shows are not covered. The amount of movies in this database depends on the amount of movies in the datasets, and does not cover all the movies in the world. I plan to use public datasets that are available online, and try to pre-process them and combine them into a centralized database which can be used for analytics. Questions that can be answered include - <br/>\n",
    "a) Which oscars was the film Titanic nominated for and which did it win? <br/>\n",
    "b) What is the highest IMDb rated movie for a particular genre? <br/>\n",
    "c) What is the highest rated movie that Steven Spielberg has directed? <br/>\n",
    "<br/>\n",
    "The possibilities are endless with more data. The end solution consists of a database in the Snowflake Schema with a fact table and multiple dimension tables which can be joined for more information. The tools I use include - Python and Postgres.\n",
    "\n",
    "## Describe and Gather Data \n",
    "The datasets that I have gathered are all public datasets available on Kaggle and the IMDb website. The details are as follows - <br/> \n",
    "1) From https://www.kaggle.com/stefanoleone992/imdb-extensive-dataset <br/> \n",
    "a) IMDb_movies.csv <br/>\n",
    "b) IMDb_names.csv <br/>\n",
    "2) From https://www.kaggle.com/stefanoleone992/rotten-tomatoes-movies-and-critic-reviews-dataset <br/>\n",
    "a) rotten_tomatoes_movies.csv <br/>\n",
    "3) From https://www.kaggle.com/unanimad/the-oscar-award <br/>\n",
    "a) the_oscar_award.csv <br/>\n",
    "4) From https://www.kaggle.com/unanimad/golden-globe-awards <br/>\n",
    "a) golden_globe_awards.csv <br/>\n",
    "5) From https://datasets.imdbws.com/ <br/>\n",
    "a) cast_movies.parquet (I have downloaded the dataset and saved as parquet since its a huge dataset) <br/>\n",
    "b) IMDB_Ratings.tsv \n",
    "<br/> <br/>\n",
    "Thus, the requirement of having from atleast 2 different sources is also covered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Read in the data here\n",
    "movies_df = pd.read_csv('data/IMDb_movies.csv')\n",
    "names_df = pd.read_csv('data/IMDb_names.csv')\n",
    "ratings_df = pd.read_csv('data/IMDB_Ratings.tsv', sep=\"\\t\")\n",
    "rt_df = pd.read_csv('data/rotten_tomatoes_movies.csv')\n",
    "cast_df = pd.read_parquet(\"data/cast_movies.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "oscar_df = pd.read_csv('data/the_oscar_award.csv')\n",
    "gg_df = pd.read_csv('data/golden_globe_awards.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Step 2: Explore and Assess the Data\n",
    "## Explore the Data \n",
    "We do some basic Exploratory Data Analysis, to check for missing values, duplicates and other potential data-quality issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Length of the Datasets\n",
    "The datasets are pretty big, and easily cover the requirements - <br/>\n",
    "a) The number of rows > 1 Million </br>\n",
    "b) Atleast 2 different formats of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies Dataset length : 85855\n",
      "Names Dataset length : 297705\n",
      "Ratings Dataset length : 1172312\n",
      "Rotten Tomatoes Dataset length : 17712\n",
      "Cast Dataset length : 836122\n",
      "Oscar Dataset length : 10395\n",
      "Golden Globes Dataset length : 7991\n"
     ]
    }
   ],
   "source": [
    "print(\"Movies Dataset length : {}\".format(len(movies_df)))\n",
    "print(\"Names Dataset length : {}\".format(len(names_df)))\n",
    "print(\"Ratings Dataset length : {}\".format(len(ratings_df)))\n",
    "print(\"Rotten Tomatoes Dataset length : {}\".format(len(rt_df)))\n",
    "print(\"Cast Dataset length : {}\".format(len(cast_df)))\n",
    "print(\"Oscar Dataset length : {}\".format(len(oscar_df)))\n",
    "print(\"Golden Globes Dataset length : {}\".format(len(gg_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Checking for Missing Values\n",
    "I check which columns contain missing values. This can help us determining which columns are useful and can be used in the datasets, also which can be used as Primary Keys, or where we can set constrains such as NOT NULL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The main dataset which will be used for the movies contains some nulls for fields like director, writer which will be resolved since I will join it with a much cleaner dataset. Most of the nulls come from income fields (which I will omit for my database), and metascore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imdb_title_id 0\n",
      "title 0\n",
      "original_title 0\n",
      "year 0\n",
      "date_published 0\n",
      "genre 0\n",
      "duration 0\n",
      "country 64\n",
      "language 833\n",
      "director 87\n",
      "writer 1572\n",
      "production_company 4455\n",
      "actors 69\n",
      "description 2115\n",
      "avg_vote 0\n",
      "votes 0\n",
      "budget 62145\n",
      "usa_gross_income 70529\n",
      "worlwide_gross_income 54839\n",
      "metascore 72550\n",
      "reviews_from_users 7597\n",
      "reviews_from_critics 11797\n"
     ]
    }
   ],
   "source": [
    "for column in movies_df.columns:\n",
    "    print(column, pd.isnull(movies_df[column]).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "A lot of people are still alive so all columns related to death will be NULL. A lot of them are missing height or birth details, possibly because they are not easily available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imdb_name_id 0\n",
      "name 0\n",
      "birth_name 0\n",
      "height 253024\n",
      "bio 93007\n",
      "birth_details 187093\n",
      "date_of_birth 187093\n",
      "place_of_birth 193713\n",
      "death_details 257772\n",
      "date_of_death 257772\n",
      "place_of_death 260667\n",
      "reason_of_death 275011\n",
      "spouses_string 252353\n",
      "spouses 0\n",
      "divorces 0\n",
      "spouses_with_children 0\n",
      "children 0\n"
     ]
    }
   ],
   "source": [
    "for column in names_df.columns:\n",
    "    print(column, pd.isnull(names_df[column]).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The next 2 datasets are from IMDb website itself, which means they are very clean, very high quality datasets, as we can see no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tconst 0\n",
      "averageRating 0\n",
      "numVotes 0\n"
     ]
    }
   ],
   "source": [
    "for column in ratings_df.columns:\n",
    "    print(column, pd.isnull(ratings_df[column]).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imdb_title_id 0\n",
      "tconst 0\n",
      "ordering 0\n",
      "nconst 0\n",
      "category 0\n",
      "job 0\n",
      "characters 0\n"
     ]
    }
   ],
   "source": [
    "for column in cast_df.columns:\n",
    "    print(column, pd.isnull(cast_df[column]).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Rotten Tomatoes dataset has less movies than the IMDb dataset, which means not every movie in IMDb dataset will get a RottenTomatoes rating. Except for critics_consensus, most of the dataset looks relatively clean. A lot of repeating fields here won't be considered since I will already take those from the IMDb dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rotten_tomatoes_link 0\n",
      "movie_title 0\n",
      "movie_info 321\n",
      "critics_consensus 8578\n",
      "content_rating 0\n",
      "genres 19\n",
      "directors 194\n",
      "authors 1542\n",
      "actors 352\n",
      "original_release_date 1166\n",
      "streaming_release_date 384\n",
      "runtime 314\n",
      "production_company 499\n",
      "tomatometer_status 44\n",
      "tomatometer_rating 44\n",
      "tomatometer_count 44\n",
      "audience_status 448\n",
      "audience_rating 296\n",
      "audience_count 297\n",
      "tomatometer_top_critics_count 0\n",
      "tomatometer_fresh_critics_count 0\n",
      "tomatometer_rotten_critics_count 0\n"
     ]
    }
   ],
   "source": [
    "for column in rt_df.columns:\n",
    "    print(column, pd.isnull(rt_df[column]).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The Awards Datasets are very clean and also very small, since they only contain information about the awardees and nominees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year_film 0\n",
      "year_ceremony 0\n",
      "ceremony 0\n",
      "category 0\n",
      "name 0\n",
      "film 304\n",
      "winner 0\n"
     ]
    }
   ],
   "source": [
    "for column in oscar_df.columns:\n",
    "    print(column, pd.isnull(oscar_df[column]).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year_film 0\n",
      "year_award 0\n",
      "ceremony 0\n",
      "category 0\n",
      "nominee 0\n",
      "film 1800\n",
      "win 0\n"
     ]
    }
   ],
   "source": [
    "for column in gg_df.columns:\n",
    "    print(column, pd.isnull(gg_df[column]).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Checking for Duplicated Data\n",
    "We see that Oscars dataset contains some duplicates which we will remove in the cleaning set. Other duplicates might be possible, but those will be taken care in the data pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies Duplicates : 0.0\n",
      "Names Duplicates : 0.0\n",
      "Ratings Duplicates : 0.0\n",
      "Rotten Tomatoes Duplicates : 0.0\n",
      "Oscars Duplicates : 5.5\n",
      "Golden Globe Duplicates : 0.0\n",
      "Cast Duplicates : 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Movies Duplicates : {}\".format(len(movies_df[movies_df.duplicated(keep=False)==True])/2))\n",
    "print(\"Names Duplicates : {}\".format(len(names_df[names_df.duplicated(keep=False)==True])/2))\n",
    "print(\"Ratings Duplicates : {}\".format(len(ratings_df[ratings_df.duplicated(keep=False)==True])/2))\n",
    "print(\"Rotten Tomatoes Duplicates : {}\".format(len(rt_df[rt_df.duplicated(keep=False)==True])/2))\n",
    "print(\"Oscars Duplicates : {}\".format(len(oscar_df[oscar_df.duplicated(keep=False)==True])/2))\n",
    "print(\"Golden Globe Duplicates : {}\".format(len(gg_df[gg_df.duplicated(keep=False)==True])/2))\n",
    "print(\"Cast Duplicates : {}\".format(len(cast_df[cast_df.duplicated(keep=False)==True])/2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Checking for Data Quality Issues \n",
    "Since some of the datasets sourced from Kaggle have been scraped from the internet, they will have data quality issues. We need to be aware of the relevant ones so that we can resolve those before our data pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Issue with Cases \n",
    "Since the movies in different datasets will be in different cases, we will have to convert all the movies to lower case during processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Other Issues\n",
    "Some of the issues came while working with the project which I will mention here and how I tackle them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1894', '1906', '1911', '1912', '1913', '1914', '1915', '1916',\n",
       "       '1917', '1918', '1919', '1920', '1921', '1922', '1923', '1924',\n",
       "       '1925', '1926', '1927', '1928', '1929', '1930', '1931', '1932',\n",
       "       '1933', '1934', '1935', '1936', '1937', '1938', '1939', '1940',\n",
       "       '1941', '1942', '1943', '1944', '1945', '1946', '1947', '1948',\n",
       "       '1949', '1950', '1951', '1952', '1953', '1954', '1955', '1956',\n",
       "       '1957', '1958', '1959', '1960', '1961', '1962', '1963', '1964',\n",
       "       '1965', '1966', '1967', '1968', '1969', '1970', '1971', '1972',\n",
       "       '1973', '1974', '1975', '1976', '1977', '1978', '1979', '1980',\n",
       "       '1981', '1982', '1983', '1984', '1985', '1986', '1987', '1988',\n",
       "       '1989', '1990', '1991', '1992', '1993', '1994', '1995', '1996',\n",
       "       '1997', '1998', '1999', '2000', '2001', '2002', '2003', '2004',\n",
       "       '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012',\n",
       "       '2013', '2014', '2015', '2016', '2017', '2018', '2019', '2020',\n",
       "       'TV Movie 2019'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We see that some of the rows contain a value \"TV Movie 2019\" for year, which will need to be cleaned\n",
    "x1 = movies_df.copy()\n",
    "x1[\"year\"] = x1.year.astype(str)\n",
    "np.unique(x1.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Remains of the Day, The',\n",
       " ' Roma ',\n",
       " '$1,000,000 Duck',\n",
       " \"'Round Midnight\",\n",
       " \"'night, Mother\"]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We see some issues in the Golden Globes Dataset which will be taken care of in the pipeline - \n",
    "#Whenever there is a comma and after the comma its either 'The' or 'A', the film name is inverted so we need to correct that\n",
    "list(np.unique(gg_df.film.dropna()))[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Cleaning Steps\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#As we saw, we need to clean the year column of movies_df \n",
    "movies_df.loc[movies_df.year == \"TV Movie 2019\", \"year\"] = 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#To clean the Golden Globes dataset, I use some custom defined functions\n",
    "def process_comma(x):\n",
    "    \"\"\"\n",
    "    This function is necessary since we need to change the order of the words in the dataset when there is a comma\n",
    "    The condition is that there should be only 2 substrings (one before and one after the comma), and if there is \n",
    "    'a' or 'the' in the end of the string. \n",
    "    Input: A string which needs to be processed \n",
    "    Output: A string which is corrected for the issue due to the comma\n",
    "    \"\"\"\n",
    "    if \",\" in x:\n",
    "        x1 = x.split(\",\")\n",
    "        if ((x1[-1] == \" a\") or (x1[-1] == \" the\")) and (len(x1)==2):\n",
    "            return x1[1][1:] + \" \" + x1[0]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "oscar_df = oscar_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "There needs to be more cleaning just as changing column names, and dropping duplicates, but all that will be performed in the data pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Step 3: Define the Data Model\n",
    "## 3.1 Conceptual Data Model\n",
    "\n",
    "Map out the conceptual data model and explain why you chose that model\n",
    "\n",
    "I will use a snowflake schema with a fact table and multiple dimension tables. The diagram is as follows - \n",
    "![title](schema.PNG)\n",
    "\n",
    "As we can see, the Movies table will be the fact table that contains information about the movie, its run-time, release date, IMDB score, Rotten Tomatoes scores, number of oscars won and number of golden globes won. The Crew table will contain a mapping from movies to names (names of actors, directors etc.) which are stored in the Names table. The Characters table contains all the characters that are played by the actors in the movies. The Oscars and Golden Globes table contain the winners and nominees for the movies, while Genres table is a mapping between movies and genres. The votes table stores the votes that each movie gets.  <br/> \n",
    "\n",
    "I have chosen this model since it is 3NF normalized and it allows me to get answers quickly based on various joins. The information is stored in such a way that each table can be updated independently. It also makes it easier to visualize and create new queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model\n",
    "\n",
    "To transfor our current dataset into the following database diagram that I have developed, we will follow the following steps - <br/> <br/>\n",
    "![title](etl_pipeline.png)\n",
    "\n",
    "<br/>\n",
    "After loading all the files and doing some basic pre-processing, we will follow certain steps to transform each file into the desired tables - <br/>\n",
    "1) Movies table will be formed by joining movies_df with ratings_df, rt_df, oscar_df and gg_df. <br/>\n",
    "2) Names table is readily available as names_df <br/>\n",
    "3) Crew table is also available as cast_df <br/>\n",
    "4) For Characters table, we have to extract the characters from the cast_df for each title <br/>\n",
    "5) Genre table will also be created from movies_df <br/>\n",
    "6) Oscars and Golden_Globes tables are readily available as gg_df and oscar_df after some processing <br/>\n",
    "7) Votes table will also be extracted from movies_df and rt_df <br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Step 4: Run Pipelines to Model the Data \n",
    "## 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Processing Movies Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dt1 = movies_df[[\"imdb_title_id\", \"original_title\", \"year\", \"duration\", \"country\", \"description\", \"metascore\"]].copy()\n",
    "#Converting to lower case to avoid any joining issues with names\n",
    "dt1[\"original_title\"] = dt1.original_title.str.lower()\n",
    "dt1 = dt1.rename(columns={\"original_title\":'Title'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Joining the ratings table to get the correct IMDb score\n",
    "ratings_df = ratings_df.rename(columns={\"tconst\":'imdb_title_id', \"averageRating\":'IMDB_rating'})\n",
    "dt2 = dt1.merge(ratings_df, on=\"imdb_title_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Processing the Rotten Tomatoes file, so that it can be merged with the movies file\n",
    "rt_df2 = rt_df[[\"movie_title\", \"original_release_date\", \"content_rating\", \"tomatometer_status\", \"tomatometer_rating\", \"tomatometer_count\", \"audience_status\", \"audience_rating\",  \"audience_count\"]].copy()\n",
    "#Following the same principle of converting tiles to lower case\n",
    "rt_df2[\"movie_title\"] = rt_df2[\"movie_title\"].str.lower()\n",
    "rt_df2 = rt_df2.rename(columns={\"movie_title\":'Title'})\n",
    "rt_df2[\"date_dt\"] = pd.to_datetime(rt_df2[\"original_release_date\"]) \n",
    "rt_df2[\"year\"] = rt_df2.date_dt.apply(lambda x: x.year)\n",
    "rt_df2 = rt_df2.drop(columns=[\"original_release_date\", \"date_dt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dt2[\"year\"] = dt2.year.astype(float)\n",
    "dt3 = dt2.merge(rt_df2, on=[\"Title\", \"year\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Creating Oscars Table\n",
    "We will just process oscar_df a bit and join it with movies_df to get the imdb_title_id which is our main key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "oscar_df = oscar_df.dropna(subset=['film'])\n",
    "oscar_df = oscar_df.rename(columns={\"film\":\"Title\", \"year_film\":'year'})\n",
    "oscar_df[\"Title\"] = oscar_df[\"Title\"].str.lower()\n",
    "o_df1 = oscar_df.merge(dt3[[\"imdb_title_id\", \"Title\", \"year\"]], on=[\"Title\", \"year\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>year_ceremony</th>\n",
       "      <th>ceremony</th>\n",
       "      <th>category</th>\n",
       "      <th>name</th>\n",
       "      <th>Title</th>\n",
       "      <th>winner</th>\n",
       "      <th>imdb_title_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1927</td>\n",
       "      <td>1928</td>\n",
       "      <td>1</td>\n",
       "      <td>ACTOR</td>\n",
       "      <td>Richard Barthelmess</td>\n",
       "      <td>the noose</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1927</td>\n",
       "      <td>1928</td>\n",
       "      <td>1</td>\n",
       "      <td>ACTOR</td>\n",
       "      <td>Emil Jannings</td>\n",
       "      <td>the last command</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1927</td>\n",
       "      <td>1928</td>\n",
       "      <td>1</td>\n",
       "      <td>ACTRESS</td>\n",
       "      <td>Louise Dresser</td>\n",
       "      <td>a ship comes in</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1927</td>\n",
       "      <td>1928</td>\n",
       "      <td>1</td>\n",
       "      <td>ACTRESS</td>\n",
       "      <td>Janet Gaynor</td>\n",
       "      <td>7th heaven</td>\n",
       "      <td>True</td>\n",
       "      <td>tt0018379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1927</td>\n",
       "      <td>1928</td>\n",
       "      <td>1</td>\n",
       "      <td>ACTRESS</td>\n",
       "      <td>Gloria Swanson</td>\n",
       "      <td>sadie thompson</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  year_ceremony  ceremony category                 name  \\\n",
       "0  1927           1928         1    ACTOR  Richard Barthelmess   \n",
       "1  1927           1928         1    ACTOR        Emil Jannings   \n",
       "2  1927           1928         1  ACTRESS       Louise Dresser   \n",
       "3  1927           1928         1  ACTRESS         Janet Gaynor   \n",
       "4  1927           1928         1  ACTRESS       Gloria Swanson   \n",
       "\n",
       "              Title  winner imdb_title_id  \n",
       "0         the noose   False           NaN  \n",
       "1  the last command    True           NaN  \n",
       "2   a ship comes in   False           NaN  \n",
       "3        7th heaven    True     tt0018379  \n",
       "4    sadie thompson   False           NaN  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year 0\n",
      "year_ceremony 0\n",
      "ceremony 0\n",
      "category 0\n",
      "name 0\n",
      "Title 0\n",
      "winner 0\n",
      "imdb_title_id 2900\n"
     ]
    }
   ],
   "source": [
    "for column in o_df1.columns:\n",
    "    print(column, pd.isnull(o_df1[column]).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#When inserting NaN's, we have to first convert it to None so SQL translates it as NULL\n",
    "#We save the processed table in output_files\n",
    "o_df1 = convert_nan(o_df1)\n",
    "o_df1.to_csv('output_files/Oscars.csv', header=False, index=False, sep=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Creating Golden_Globes Table\n",
    "Same as the oscars table, we have to process the Golden Globes table a bit, but this time, its a bit more code since the file is more unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "gg_only_movies = gg_df[~gg_df.category.str.contains(\"Television\")].copy()\n",
    "gg_only_movies[\"film\"] = np.where(pd.isnull(gg_only_movies.film), gg_only_movies.nominee, gg_only_movies.film)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "gg_only_movies = gg_only_movies.rename(columns={\"film\":\"Title\", \"year_film\":'year'})\n",
    "gg_only_movies[\"Title\"] = gg_only_movies[\"Title\"].str.lower().str.strip()\n",
    "gg_only_movies[\"Title\"] = gg_only_movies[\"Title\"].apply(lambda x: process_comma(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "gg_df1 = gg_only_movies.merge(dt3[[\"imdb_title_id\", \"Title\", \"year\"]], on=[\"Title\", \"year\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>year_award</th>\n",
       "      <th>ceremony</th>\n",
       "      <th>category</th>\n",
       "      <th>nominee</th>\n",
       "      <th>Title</th>\n",
       "      <th>win</th>\n",
       "      <th>imdb_title_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1943</td>\n",
       "      <td>1944</td>\n",
       "      <td>1</td>\n",
       "      <td>Best Performance by an Actress in a Supporting...</td>\n",
       "      <td>Katina Paxinou</td>\n",
       "      <td>for whom the bell tolls</td>\n",
       "      <td>True</td>\n",
       "      <td>tt0035896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1943</td>\n",
       "      <td>1944</td>\n",
       "      <td>1</td>\n",
       "      <td>Best Performance by an Actor in a Supporting R...</td>\n",
       "      <td>Akim Tamiroff</td>\n",
       "      <td>for whom the bell tolls</td>\n",
       "      <td>True</td>\n",
       "      <td>tt0035896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1943</td>\n",
       "      <td>1944</td>\n",
       "      <td>1</td>\n",
       "      <td>Best Director - Motion Picture</td>\n",
       "      <td>Henry King</td>\n",
       "      <td>the song of bernadette</td>\n",
       "      <td>True</td>\n",
       "      <td>tt0036377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1943</td>\n",
       "      <td>1944</td>\n",
       "      <td>1</td>\n",
       "      <td>Picture</td>\n",
       "      <td>The Song Of Bernadette</td>\n",
       "      <td>the song of bernadette</td>\n",
       "      <td>True</td>\n",
       "      <td>tt0036377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1943</td>\n",
       "      <td>1944</td>\n",
       "      <td>1</td>\n",
       "      <td>Actress In A Leading Role</td>\n",
       "      <td>Jennifer Jones</td>\n",
       "      <td>the song of bernadette</td>\n",
       "      <td>True</td>\n",
       "      <td>tt0036377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  year_award  ceremony  \\\n",
       "0  1943        1944         1   \n",
       "1  1943        1944         1   \n",
       "2  1943        1944         1   \n",
       "3  1943        1944         1   \n",
       "4  1943        1944         1   \n",
       "\n",
       "                                            category                 nominee  \\\n",
       "0  Best Performance by an Actress in a Supporting...          Katina Paxinou   \n",
       "1  Best Performance by an Actor in a Supporting R...           Akim Tamiroff   \n",
       "2                     Best Director - Motion Picture              Henry King   \n",
       "3                                            Picture  The Song Of Bernadette   \n",
       "4                          Actress In A Leading Role          Jennifer Jones   \n",
       "\n",
       "                     Title   win imdb_title_id  \n",
       "0  for whom the bell tolls  True     tt0035896  \n",
       "1  for whom the bell tolls  True     tt0035896  \n",
       "2   the song of bernadette  True     tt0036377  \n",
       "3   the song of bernadette  True     tt0036377  \n",
       "4   the song of bernadette  True     tt0036377  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gg_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year 0\n",
      "year_award 0\n",
      "ceremony 0\n",
      "category 0\n",
      "nominee 0\n",
      "Title 0\n",
      "win 0\n",
      "imdb_title_id 948\n"
     ]
    }
   ],
   "source": [
    "for column in gg_df1.columns:\n",
    "    print(column, pd.isnull(gg_df1[column]).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#When inserting NaN's, we have to first convert it to None so SQL translates it as NULL\n",
    "gg_df1 = convert_nan(gg_df1)\n",
    "gg_df1 = gg_df1.drop_duplicates(subset=[\"year\",\"year_award\",\"ceremony\",\"category\",\"nominee\",\"Title\",\"win\"])\n",
    "str_col_list = [\"category\",\"nominee\",\"Title\"]\n",
    "for column in str_col_list:\n",
    "    gg_df1[column] = gg_df1[column].str.strip()\n",
    "gg_df1.to_csv('output_files/Golden_Globes.csv', header=False, index=False, sep=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Creating Movies Table \n",
    "Now that we have processed the Oscars and Golden Globes table, we can aggregate it to calculate additional fields, and add that to our fact table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "o_df2 = o_df1.groupby(by=[\"imdb_title_id\", \"year\"], as_index=False).agg({\"winner\":'sum', \"Title\":'count'})\n",
    "o_df2 = o_df2.rename(columns={\"winner\":\"num_oscars\", \"Title\":'num_nominations_oscars'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "gg_df2 = gg_df1.groupby(by=[\"imdb_title_id\", \"year\"], as_index=False).agg({\"win\":'sum', \"Title\":'count'})\n",
    "gg_df2 = gg_df2.rename(columns={\"win\":\"num_golden_globes\", \"Title\":'num_nominations_globes'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dt4 = dt3.merge(o_df2, on=[\"imdb_title_id\", \"year\"], how=\"left\").merge(gg_df2, on=[\"imdb_title_id\", \"year\"], how=\"left\")\n",
    "dt4[[\"num_oscars\", \"num_nominations_oscars\", \"num_golden_globes\", \"num_nominations_globes\"]] = dt4[[\"num_oscars\", \"num_nominations_oscars\", \"num_golden_globes\", \"num_nominations_globes\"]].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "movies = dt4[['imdb_title_id', 'Title', 'year', 'duration', 'country', 'description',\n",
    "              'metascore', 'IMDB_rating', 'content_rating', 'tomatometer_status', 'tomatometer_rating', \n",
    "              'audience_status', 'audience_rating', 'num_oscars',\n",
    "              'num_nominations_oscars', 'num_golden_globes', 'num_nominations_globes']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imdb_title_id</th>\n",
       "      <th>Title</th>\n",
       "      <th>year</th>\n",
       "      <th>duration</th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>metascore</th>\n",
       "      <th>IMDB_rating</th>\n",
       "      <th>content_rating</th>\n",
       "      <th>tomatometer_status</th>\n",
       "      <th>tomatometer_rating</th>\n",
       "      <th>audience_status</th>\n",
       "      <th>audience_rating</th>\n",
       "      <th>num_oscars</th>\n",
       "      <th>num_nominations_oscars</th>\n",
       "      <th>num_golden_globes</th>\n",
       "      <th>num_nominations_globes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0000009</td>\n",
       "      <td>miss jerry</td>\n",
       "      <td>1894.0</td>\n",
       "      <td>45</td>\n",
       "      <td>USA</td>\n",
       "      <td>The adventures of a female reporter in the 1890s.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0000574</td>\n",
       "      <td>the story of the kelly gang</td>\n",
       "      <td>1906.0</td>\n",
       "      <td>70</td>\n",
       "      <td>Australia</td>\n",
       "      <td>True story of notorious Australian outlaw Ned ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0001892</td>\n",
       "      <td>den sorte drøm</td>\n",
       "      <td>1911.0</td>\n",
       "      <td>53</td>\n",
       "      <td>Germany, Denmark</td>\n",
       "      <td>Two men of high rank are both wooing the beaut...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0002101</td>\n",
       "      <td>cleopatra</td>\n",
       "      <td>1912.0</td>\n",
       "      <td>100</td>\n",
       "      <td>USA</td>\n",
       "      <td>The fabled queen of Egypt's affair with Roman ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0002130</td>\n",
       "      <td>l'inferno</td>\n",
       "      <td>1911.0</td>\n",
       "      <td>68</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Loosely adapted from Dante's Divine Comedy and...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  imdb_title_id                        Title    year  duration  \\\n",
       "0     tt0000009                   miss jerry  1894.0        45   \n",
       "1     tt0000574  the story of the kelly gang  1906.0        70   \n",
       "2     tt0001892               den sorte drøm  1911.0        53   \n",
       "3     tt0002101                    cleopatra  1912.0       100   \n",
       "4     tt0002130                    l'inferno  1911.0        68   \n",
       "\n",
       "            country                                        description  \\\n",
       "0               USA  The adventures of a female reporter in the 1890s.   \n",
       "1         Australia  True story of notorious Australian outlaw Ned ...   \n",
       "2  Germany, Denmark  Two men of high rank are both wooing the beaut...   \n",
       "3               USA  The fabled queen of Egypt's affair with Roman ...   \n",
       "4             Italy  Loosely adapted from Dante's Divine Comedy and...   \n",
       "\n",
       "   metascore  IMDB_rating content_rating tomatometer_status  \\\n",
       "0        NaN          5.8            NaN                NaN   \n",
       "1        NaN          6.1            NaN                NaN   \n",
       "2        NaN          5.9            NaN                NaN   \n",
       "3        NaN          5.1            NaN                NaN   \n",
       "4        NaN          7.1            NaN                NaN   \n",
       "\n",
       "   tomatometer_rating audience_status  audience_rating  num_oscars  \\\n",
       "0                 NaN             NaN              NaN         0.0   \n",
       "1                 NaN             NaN              NaN         0.0   \n",
       "2                 NaN             NaN              NaN         0.0   \n",
       "3                 NaN             NaN              NaN         0.0   \n",
       "4                 NaN             NaN              NaN         0.0   \n",
       "\n",
       "   num_nominations_oscars  num_golden_globes  num_nominations_globes  \n",
       "0                     0.0                0.0                     0.0  \n",
       "1                     0.0                0.0                     0.0  \n",
       "2                     0.0                0.0                     0.0  \n",
       "3                     0.0                0.0                     0.0  \n",
       "4                     0.0                0.0                     0.0  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imdb_title_id 0\n",
      "Title 0\n",
      "year 0\n",
      "duration 0\n",
      "country 64\n",
      "description 2115\n",
      "metascore 72539\n",
      "IMDB_rating 0\n",
      "content_rating 76450\n",
      "tomatometer_status 76459\n",
      "tomatometer_rating 76459\n",
      "audience_status 76577\n",
      "audience_rating 76473\n",
      "num_oscars 0\n",
      "num_nominations_oscars 0\n",
      "num_golden_globes 0\n",
      "num_nominations_globes 0\n"
     ]
    }
   ],
   "source": [
    "for column in movies.columns:\n",
    "    print(column, pd.isnull(movies[column]).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#When inserting NaN's, we have to first convert it to None so SQL translates it as NULL\n",
    "movies = convert_nan(movies)\n",
    "movies = movies.drop_duplicates(subset=[\"imdb_title_id\"])\n",
    "movies.to_csv('output_files/Movies.csv', header=False, index=False, sep=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Creating Other Dimension Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Creating Votes Table\n",
    "We will extract the votes information from dt4 so that we can update this table without affecting the fact table too much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "votes = dt4[['imdb_title_id', 'numVotes', 'tomatometer_count', 'audience_count']].copy()\n",
    "votes = votes.rename(columns={\"numVotes\":'IMDB_votes', \"tomatometer_count\":'RT_votes_critics', \"audience_count\":'RT_votes_audience'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imdb_title_id</th>\n",
       "      <th>IMDB_votes</th>\n",
       "      <th>RT_votes_critics</th>\n",
       "      <th>RT_votes_audience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0000009</td>\n",
       "      <td>156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0000574</td>\n",
       "      <td>643</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0001892</td>\n",
       "      <td>195</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0002101</td>\n",
       "      <td>463</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0002130</td>\n",
       "      <td>2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  imdb_title_id  IMDB_votes  RT_votes_critics  RT_votes_audience\n",
       "0     tt0000009         156               NaN                NaN\n",
       "1     tt0000574         643               NaN                NaN\n",
       "2     tt0001892         195               NaN                NaN\n",
       "3     tt0002101         463               NaN                NaN\n",
       "4     tt0002130        2500               NaN                NaN"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "votes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imdb_title_id 0\n",
      "IMDB_votes 0\n",
      "RT_votes_critics 76459\n",
      "RT_votes_audience 76474\n"
     ]
    }
   ],
   "source": [
    "for column in votes.columns:\n",
    "    print(column, pd.isnull(votes[column]).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "votes = convert_nan(votes)\n",
    "votes = votes.drop_duplicates(subset=[\"imdb_title_id\"])\n",
    "votes.to_csv('output_files/Votes.csv', header=False, index=False, sep=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Creating Genres Table\n",
    "Since we want our database to be normalized, there needs to be a separate Genre table which lists for each movie, all the different genres. We will extract this information from movie_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "genre_df1 = movies_df[[\"imdb_title_id\", \"genre\"]].copy()\n",
    "list_movies = []\n",
    "list_genres = []\n",
    "for i in range(len(genre_df1)):\n",
    "    for genre in genre_df1[\"genre\"][i].split(\",\"):\n",
    "        list_movies.append(genre_df1[\"imdb_title_id\"][i])\n",
    "        list_genres.append(genre.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Action' 'Adult' 'Adventure' 'Animation' 'Biography' 'Comedy' 'Crime'\n",
      " 'Documentary' 'Drama' 'Family' 'Fantasy' 'Film-Noir' 'History' 'Horror'\n",
      " 'Music' 'Musical' 'Mystery' 'News' 'Reality-TV' 'Romance' 'Sci-Fi'\n",
      " 'Sport' 'Thriller' 'War' 'Western']\n"
     ]
    }
   ],
   "source": [
    "assert(len(list_movies)==len(list_genres))\n",
    "print(np.unique(list_genres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "genre_df2 = pd.DataFrame()\n",
    "genre_df2[\"Genre\"] = pd.Series(list_genres)\n",
    "genre_df2[\"imdb_title_id\"] = pd.Series(list_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genre</th>\n",
       "      <th>imdb_title_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Romance</td>\n",
       "      <td>tt0000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Biography</td>\n",
       "      <td>tt0000574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Crime</td>\n",
       "      <td>tt0000574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Drama</td>\n",
       "      <td>tt0000574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Drama</td>\n",
       "      <td>tt0001892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Genre imdb_title_id\n",
       "0    Romance     tt0000009\n",
       "1  Biography     tt0000574\n",
       "2      Crime     tt0000574\n",
       "3      Drama     tt0000574\n",
       "4      Drama     tt0001892"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "genre_df2 = genre_df2.drop_duplicates()\n",
    "genre_df2.to_csv('output_files/Genres.csv', header=False, index=False, sep=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Creating Crew Table\n",
    "The cast_movies.parquet file already contains the format we want, but we just have to pre-process the data a bit to create a list for characters, which would later be used for the characters dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_list_of_characters(x):\n",
    "    y = []\n",
    "    if(type(x) != list):\n",
    "        print(x)\n",
    "    for i in x:\n",
    "        y.append(i.replace(\"[\",\"\").replace(\"]\",\"\").strip('\"').strip(\" \").replace(\"\\\\N\", \"\"))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "cast_df1 = cast_df.drop(columns=[\"tconst\"])\n",
    "cast_df1[\"characters\"] = cast_df1.characters.str.split(\",\")\n",
    "cast_df1[\"characters\"] = cast_df1.characters.apply(lambda x: get_list_of_characters(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "cast_df2 = cast_df1.replace(\"\\\\N\", np.NaN).rename(columns={\"nconst\":\"imdb_name_id\"})\n",
    "cast_df2 = cast_df2.drop_duplicates(subset=[\"imdb_title_id\", \"imdb_name_id\", \"category\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imdb_title_id</th>\n",
       "      <th>ordering</th>\n",
       "      <th>imdb_name_id</th>\n",
       "      <th>category</th>\n",
       "      <th>job</th>\n",
       "      <th>characters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0000009</td>\n",
       "      <td>1</td>\n",
       "      <td>nm0063086</td>\n",
       "      <td>actress</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Miss Geraldine Holbrook (Miss Jerry)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0000009</td>\n",
       "      <td>2</td>\n",
       "      <td>nm0183823</td>\n",
       "      <td>actor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Mr. Hamilton]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0000009</td>\n",
       "      <td>3</td>\n",
       "      <td>nm1309758</td>\n",
       "      <td>actor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Chauncey Depew - the Director of the New York...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0000009</td>\n",
       "      <td>4</td>\n",
       "      <td>nm0085156</td>\n",
       "      <td>director</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0000574</td>\n",
       "      <td>10</td>\n",
       "      <td>nm0675239</td>\n",
       "      <td>cinematographer</td>\n",
       "      <td>director of photography</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  imdb_title_id  ordering imdb_name_id         category  \\\n",
       "0     tt0000009         1    nm0063086          actress   \n",
       "1     tt0000009         2    nm0183823            actor   \n",
       "2     tt0000009         3    nm1309758            actor   \n",
       "3     tt0000009         4    nm0085156         director   \n",
       "4     tt0000574        10    nm0675239  cinematographer   \n",
       "\n",
       "                       job                                         characters  \n",
       "0                      NaN             [Miss Geraldine Holbrook (Miss Jerry)]  \n",
       "1                      NaN                                     [Mr. Hamilton]  \n",
       "2                      NaN  [Chauncey Depew - the Director of the New York...  \n",
       "3                      NaN                                                 []  \n",
       "4  director of photography                                                 []  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cast_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imdb_title_id 0\n",
      "ordering 0\n",
      "imdb_name_id 0\n",
      "category 0\n",
      "job 621377\n",
      "characters 0\n"
     ]
    }
   ],
   "source": [
    "for column in cast_df2.columns:\n",
    "    print(column, pd.isnull(cast_df2[column]).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "crew = cast_df2.drop(columns=[\"characters\"])\n",
    "crew = crew.drop_duplicates(subset=[\"imdb_title_id\", \"imdb_name_id\", \"category\"])\n",
    "crew.to_csv('output_files/Crew.csv', header=False, index=False, sep=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Creating Names Table\n",
    "For actual information on the cast, the IMDb_names.csv file contains all the information we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "names_df1 = names_df.drop(columns = ['spouses_string', 'spouses', 'divorces', 'spouses_with_children', 'children'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imdb_name_id</th>\n",
       "      <th>name</th>\n",
       "      <th>birth_name</th>\n",
       "      <th>height</th>\n",
       "      <th>bio</th>\n",
       "      <th>birth_details</th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>place_of_birth</th>\n",
       "      <th>death_details</th>\n",
       "      <th>date_of_death</th>\n",
       "      <th>place_of_death</th>\n",
       "      <th>reason_of_death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nm0000001</td>\n",
       "      <td>Fred Astaire</td>\n",
       "      <td>Frederic Austerlitz Jr.</td>\n",
       "      <td>177.0</td>\n",
       "      <td>Fred Astaire was born in Omaha, Nebraska, to J...</td>\n",
       "      <td>May 10, 1899 in Omaha, Nebraska, USA</td>\n",
       "      <td>1899-05-10</td>\n",
       "      <td>Omaha, Nebraska, USA</td>\n",
       "      <td>June 22, 1987 in Los Angeles, California, USA ...</td>\n",
       "      <td>1987-06-22</td>\n",
       "      <td>Los Angeles, California, USA</td>\n",
       "      <td>pneumonia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nm0000002</td>\n",
       "      <td>Lauren Bacall</td>\n",
       "      <td>Betty Joan Perske</td>\n",
       "      <td>174.0</td>\n",
       "      <td>Lauren Bacall was born Betty Joan Perske on Se...</td>\n",
       "      <td>September 16, 1924 in The Bronx, New York City...</td>\n",
       "      <td>1924-09-16</td>\n",
       "      <td>The Bronx, New York City, New York, USA</td>\n",
       "      <td>August 12, 2014 in New York City, New York, US...</td>\n",
       "      <td>2014-08-12</td>\n",
       "      <td>New York City, New York, USA</td>\n",
       "      <td>stroke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nm0000003</td>\n",
       "      <td>Brigitte Bardot</td>\n",
       "      <td>Brigitte Bardot</td>\n",
       "      <td>166.0</td>\n",
       "      <td>Brigitte Bardot was born on September 28, 1934...</td>\n",
       "      <td>September 28, 1934 in Paris, France</td>\n",
       "      <td>1934-09-28</td>\n",
       "      <td>Paris, France</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nm0000004</td>\n",
       "      <td>John Belushi</td>\n",
       "      <td>John Adam Belushi</td>\n",
       "      <td>170.0</td>\n",
       "      <td>John Belushi was born in Chicago, Illinois, US...</td>\n",
       "      <td>January 24, 1949 in Chicago, Illinois, USA</td>\n",
       "      <td>1949-01-24</td>\n",
       "      <td>Chicago, Illinois, USA</td>\n",
       "      <td>March 5, 1982 in Hollywood, Los Angeles, Calif...</td>\n",
       "      <td>1982-03-05</td>\n",
       "      <td>Hollywood, Los Angeles, California, USA</td>\n",
       "      <td>acute cocaine and heroin intoxication</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nm0000005</td>\n",
       "      <td>Ingmar Bergman</td>\n",
       "      <td>Ernst Ingmar Bergman</td>\n",
       "      <td>179.0</td>\n",
       "      <td>Ernst Ingmar Bergman was born July 14, 1918, t...</td>\n",
       "      <td>July 14, 1918 in Uppsala, Uppsala län, Sweden</td>\n",
       "      <td>1918-07-14</td>\n",
       "      <td>Uppsala, Uppsala län, Sweden</td>\n",
       "      <td>July 30, 2007 in Fårö, Gotlands län, Sweden  (...</td>\n",
       "      <td>2007-07-30</td>\n",
       "      <td>Fårö, Gotlands län, Sweden</td>\n",
       "      <td>natural causes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  imdb_name_id             name               birth_name  height  \\\n",
       "0    nm0000001     Fred Astaire  Frederic Austerlitz Jr.   177.0   \n",
       "1    nm0000002    Lauren Bacall        Betty Joan Perske   174.0   \n",
       "2    nm0000003  Brigitte Bardot          Brigitte Bardot   166.0   \n",
       "3    nm0000004     John Belushi        John Adam Belushi   170.0   \n",
       "4    nm0000005   Ingmar Bergman     Ernst Ingmar Bergman   179.0   \n",
       "\n",
       "                                                 bio  \\\n",
       "0  Fred Astaire was born in Omaha, Nebraska, to J...   \n",
       "1  Lauren Bacall was born Betty Joan Perske on Se...   \n",
       "2  Brigitte Bardot was born on September 28, 1934...   \n",
       "3  John Belushi was born in Chicago, Illinois, US...   \n",
       "4  Ernst Ingmar Bergman was born July 14, 1918, t...   \n",
       "\n",
       "                                       birth_details date_of_birth  \\\n",
       "0               May 10, 1899 in Omaha, Nebraska, USA    1899-05-10   \n",
       "1  September 16, 1924 in The Bronx, New York City...    1924-09-16   \n",
       "2                September 28, 1934 in Paris, France    1934-09-28   \n",
       "3         January 24, 1949 in Chicago, Illinois, USA    1949-01-24   \n",
       "4      July 14, 1918 in Uppsala, Uppsala län, Sweden    1918-07-14   \n",
       "\n",
       "                            place_of_birth  \\\n",
       "0                     Omaha, Nebraska, USA   \n",
       "1  The Bronx, New York City, New York, USA   \n",
       "2                            Paris, France   \n",
       "3                   Chicago, Illinois, USA   \n",
       "4             Uppsala, Uppsala län, Sweden   \n",
       "\n",
       "                                       death_details date_of_death  \\\n",
       "0  June 22, 1987 in Los Angeles, California, USA ...    1987-06-22   \n",
       "1  August 12, 2014 in New York City, New York, US...    2014-08-12   \n",
       "2                                                NaN           NaN   \n",
       "3  March 5, 1982 in Hollywood, Los Angeles, Calif...    1982-03-05   \n",
       "4  July 30, 2007 in Fårö, Gotlands län, Sweden  (...    2007-07-30   \n",
       "\n",
       "                              place_of_death  \\\n",
       "0             Los Angeles, California, USA     \n",
       "1             New York City, New York, USA     \n",
       "2                                        NaN   \n",
       "3  Hollywood, Los Angeles, California, USA     \n",
       "4               Fårö, Gotlands län, Sweden     \n",
       "\n",
       "                         reason_of_death  \n",
       "0                              pneumonia  \n",
       "1                                 stroke  \n",
       "2                                    NaN  \n",
       "3  acute cocaine and heroin intoxication  \n",
       "4                         natural causes  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imdb_name_id 0\n",
      "name 0\n",
      "birth_name 0\n",
      "height 253024\n",
      "bio 93007\n",
      "birth_details 187093\n",
      "date_of_birth 187093\n",
      "place_of_birth 193713\n",
      "death_details 257772\n",
      "date_of_death 257772\n",
      "place_of_death 260667\n",
      "reason_of_death 275011\n"
     ]
    }
   ],
   "source": [
    "for column in names_df1.columns:\n",
    "    print(column, pd.isnull(names_df1[column]).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def remove_alphabets(x):\n",
    "    \"\"\"\n",
    "    We have some alphabets in 2 columns - date_of_birth / date_of_death so we use regex to just remove those \n",
    "    Input: Unprocessed string \n",
    "    Output: Processed string without alphabets\n",
    "    \"\"\"\n",
    "    if not pd.isnull(x):\n",
    "        return re.sub(r'[A-Za-z]', '', x).strip()\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "names_df1[\"date_of_birth\"] = names_df1[\"date_of_birth\"].apply(lambda x: remove_alphabets(x))\n",
    "names_df1[\"date_of_death\"] = names_df1[\"date_of_death\"].apply(lambda x: remove_alphabets(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "names_df1 = names_df1.drop_duplicates(subset=[\"imdb_name_id\"])\n",
    "names_df1.to_csv('output_files/Names.csv', header=False, index=False, sep=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Creating Characters Table\n",
    "We map for a particular movie, for a particular person and for a particular category, what characters the person plays. We do this so that the database is still normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Each character gets one row\n",
    "character_df = cast_df2[cast_df2.characters.apply(lambda x: x!=[\"\"])].copy().reset_index(drop=True)\n",
    "character_df = character_df[[\"imdb_title_id\", \"imdb_name_id\", \"category\", \"characters\"]].copy()\n",
    "list_movies = []\n",
    "list_names = []\n",
    "list_category = []\n",
    "list_characters = []\n",
    "for i in range(len(character_df)):\n",
    "    for character in character_df[\"characters\"][i]:\n",
    "        list_movies.append(character_df[\"imdb_title_id\"][i])\n",
    "        list_names.append(character_df[\"imdb_name_id\"][i])\n",
    "        list_category.append(character_df[\"category\"][i])\n",
    "        list_characters.append(character)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "assert(len(list_movies) == len(list_names))\n",
    "assert(len(list_names) == len(list_category))\n",
    "assert(len(list_category)==len(list_characters))\n",
    "character_df2 = pd.DataFrame()\n",
    "character_df2[\"imdb_title_id\"] = list_movies\n",
    "character_df2[\"imdb_name_id\"] = list_names\n",
    "character_df2[\"category\"] = list_category\n",
    "character_df2[\"character\"] = list_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imdb_title_id</th>\n",
       "      <th>imdb_name_id</th>\n",
       "      <th>category</th>\n",
       "      <th>character</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0000009</td>\n",
       "      <td>nm0063086</td>\n",
       "      <td>actress</td>\n",
       "      <td>Miss Geraldine Holbrook (Miss Jerry)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0000009</td>\n",
       "      <td>nm0183823</td>\n",
       "      <td>actor</td>\n",
       "      <td>Mr. Hamilton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0000009</td>\n",
       "      <td>nm1309758</td>\n",
       "      <td>actor</td>\n",
       "      <td>Chauncey Depew - the Director of the New York ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0000574</td>\n",
       "      <td>nm0846887</td>\n",
       "      <td>actress</td>\n",
       "      <td>Kate Kelly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0000574</td>\n",
       "      <td>nm0846894</td>\n",
       "      <td>actor</td>\n",
       "      <td>School Master</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  imdb_title_id imdb_name_id category  \\\n",
       "0     tt0000009    nm0063086  actress   \n",
       "1     tt0000009    nm0183823    actor   \n",
       "2     tt0000009    nm1309758    actor   \n",
       "3     tt0000574    nm0846887  actress   \n",
       "4     tt0000574    nm0846894    actor   \n",
       "\n",
       "                                           character  \n",
       "0               Miss Geraldine Holbrook (Miss Jerry)  \n",
       "1                                       Mr. Hamilton  \n",
       "2  Chauncey Depew - the Director of the New York ...  \n",
       "3                                         Kate Kelly  \n",
       "4                                      School Master  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "character_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imdb_title_id 0\n",
      "imdb_name_id 0\n",
      "category 0\n",
      "character 0\n"
     ]
    }
   ],
   "source": [
    "for column in character_df2.columns:\n",
    "    print(column, pd.isnull(character_df2[column]).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "character_df2.to_csv('output_files/Characters.csv', header=False, index=False, sep=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Loading our processed data to the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def load_table(table_name, file_path, cur):\n",
    "    f = open(file_path, 'r')\n",
    "    cur.copy_from(f, table_name, sep=\"|\", null='')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting data into Movies\n",
      "Inserting data into Crew\n",
      "Inserting data into Names\n",
      "Inserting data into Characters\n",
      "Inserting data into Genres\n",
      "Inserting data into Votes\n",
      "Inserting data into Oscars\n",
      "Inserting data into Golden_Globes\n"
     ]
    }
   ],
   "source": [
    "tables = [\"Movies\", \"Crew\", \"Names\", \"Characters\", \"Genres\", \"Votes\", \"Oscars\", \"Golden_Globes\"]\n",
    "for table_name in tables:\n",
    "    print(\"Inserting data into {}\".format(table_name))\n",
    "    file_path = 'output_files/{}.csv'.format(table_name)\n",
    "    load_table(table_name, file_path, cur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 4.2 Data Quality Checks\n",
    "Data Quality Checks are important since they will tell us whether our ETL pipeline worked as expected. I will perform 2 checks on data quality and 1 check on looking at the data for a particular movie - Inception\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Quality Check for Nulls for Genres Table\n",
    "We saw that Genres table did not have any nulls, so lets check that if it is true in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We expect no result from this query and indeed, this is what we see\n",
    "cur.execute(\"SELECT * FROM Genres where genre IS NULL\")\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Quality Check for Total Rows for Oscars Table\n",
    "As expected, we see the same number of rows in the database and our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10085,)]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute(\"SELECT COUNT(*) FROM Oscars\")\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10085\n"
     ]
    }
   ],
   "source": [
    "print(len(o_df1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Fact Table Check for Movie Inception\n",
    "I want to just see the data that our database contains for one of my favorite movies!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tt1375666',\n",
       "  'inception',\n",
       "  2010,\n",
       "  148,\n",
       "  'USA, UK',\n",
       "  'A thief who steals corporate secrets through the use of dream-sharing technology is given the inverse task of planting an idea into the mind of a C.E.O.',\n",
       "  74.0,\n",
       "  8.8,\n",
       "  'PG-13',\n",
       "  'Certified-Fresh',\n",
       "  87.0,\n",
       "  'Upright',\n",
       "  91.0,\n",
       "  4,\n",
       "  8,\n",
       "  0,\n",
       "  4)]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute(\"\"\" \n",
    "SELECT * from Movies where title = 'inception'\n",
    "\"\"\")\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Thus we see the rating, Rotten Tomato rating, the number of Oscars won (4). Let's also see what Genre it is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Action', 'inception'), ('Adventure', 'inception'), ('Sci-Fi', 'inception')]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute(\"\"\" \n",
    "SELECT genre, title from Movies M\n",
    "JOIN Genres G on G.imdb_title_id = M.imdb_title_id\n",
    "where title = 'inception'\n",
    "\"\"\")\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "So we see that Inception is classified as Action, Adventure & Sci-Fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 4.3 Data dictionary \n",
    "The Data Dictionary is in the Excel File - Data Dictionary.xlsx. Each tab contains the dictionary for one table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Step 5: Complete Project Write Up\n",
    "<b>- Clearly state the rationale for the choice of tools and technologies for the project. </b> <br/>\n",
    "I chose to code the project in Python because of the ease of using the language and the variety of tools. Since I wanted to create a Relational Database, I chose to use Postgres because of its easy support with Python <br/> <br/>\n",
    "\n",
    "<b>* Propose how often the data should be updated and why.</b> <br/>\n",
    "The tables such as Movies, Names, Votes etc should ideally be updated daily, since there can always be new movies and new ratings. For tables such as Oscars and Golden Globes, they can be updated once every year. <br/> <br/>\n",
    "\n",
    "<b>* Write a description of how you would approach the problem differently under the following scenarios:</b> <br/>\n",
    " <b>* The data was increased by 100x.</b>\n",
    " If the data is increased by 100x which is possible if you include all the movies in the world, the problem would be approached a bit differently. I would use Spark for all the processing, and store parquet files. For reliability, elasticity and security, moving the solution to a Cloud Provider like AWS would have to be considered <br/>\n",
    " \n",
    " <b>* The data populates a dashboard that must be updated on a daily basis by 7am every day.</b>\n",
    " If there is a dashboard that must be updated everyday, there would need to be an Airflow pipeline that would update the database every night, so that there is always the latest information. <br/>\n",
    " \n",
    " <b>* The database needed to be accessed by 100+ people.</b>\n",
    " If we need to manage the access rights of the database and the people, then its better to use Cloud services. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
